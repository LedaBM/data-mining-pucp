{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://yann.lecun.com/exdb/mnist/\n",
    "\n",
    "Base de datos de digitos escritos a mano.\n",
    "\n",
    "* 60,000 imágenes de entrenamiento.\n",
    "* 10,000 imágenes de test.\n",
    "\n",
    "Cada imagen es de 28x28, en escala de grises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manuel/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 11s 1us/step\n",
      "Train -> x: (60000, 28, 28)\n",
      "         y: (60000,)\n",
      "Test -> x: (10000, 28, 28)\n",
      "        y: (10000,)\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "print(f'Train -> x: {x_train.shape}')\n",
    "print(f'         y: {y_train.shape}')\n",
    "print(f'Test -> x: {x_test.shape}')\n",
    "print(f'        y: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veamos una muestra\n",
    "plt.imshow(x_train[0], 'gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ajustamos las dimensiones de las imágenes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para usar las imágenes en una multiplicación de matrices, esta necesita tener sólo 2 dimensiones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape([60000, 28*28])\n",
    "x_test = x_test.reshape([10000, 28*28])\n",
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podemos usar el reshape de nuevo, para mostrar la imagen\n",
    "plt.imshow(x_train[0].reshape([28,28]), 'gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definimos un modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "lr = 0.01\n",
    "bs = 256\n",
    "nb = math.ceil(len(x_train)/bs) # Nro de batches\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(784,)),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(SGD(lr), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "# La pérdida 'sparse_categorical_crossentropy' realiza automaticamente la conversión\n",
    "# del target a one-hot encoding.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usemos el método de Learning rate finder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from custom_callbacks import LrFinder, reset_weights\n",
    "\n",
    "lr_finder = LrFinder(nb)\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=bs, callbacks=[lr_finder]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_finder.plot_lr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_finder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 2e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reseteamos los pesos y compilamos el modelo con el nuevo lr\n",
    "reset_weights(model)\n",
    "model.compile(SGD(lr), loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "log = model.fit(x_train, y_train, batch_size=bs, epochs=6, validation_data=[x_test, y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_results(model, log, cycling=False):\n",
    "    loss, acc = model.evaluate(x_test, y_test, batch_size=512, verbose=False)\n",
    "    print(f'Loss     = {loss:.4f}')\n",
    "    print(f'Accuracy = {acc:.4f}')\n",
    "    \n",
    "    val_loss = log.history['val_loss']\n",
    "    val_acc = log.history['val_acc']\n",
    "    if cycling:\n",
    "        val_loss += [loss]\n",
    "        val_acc += [acc]\n",
    "        \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14,4))\n",
    "    ax1, ax2 = axes\n",
    "    ax1.plot(log.history['loss'], label='train')\n",
    "    ax1.plot(val_loss, label='test')\n",
    "    ax1.set_xlabel('epoch'); ax1.set_ylabel('loss')\n",
    "    ax2.plot(log.history['acc'], label='train')\n",
    "    ax2.plot(val_acc, label='test')\n",
    "    ax2.set_xlabel('epoch'); ax2.set_ylabel('accuracy')\n",
    "    for ax in axes: ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_results(model, log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cycling learning rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from custom_callbacks import CycleLearner\n",
    "\n",
    "cycle_learner = CycleLearner(lr, nb, n_cycle=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_weights(model)\n",
    "log = model.fit(x_train, y_train, batch_size=bs, epochs=100,\n",
    "                validation_data=[x_test, y_test], callbacks=[cycle_learner])\n",
    "# Nota: la cantidad de epocas la va a controlar el callback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cycle_learner.plot_lr()\n",
    "show_results(model, log, cycling=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# El parametro \"cycle_mult\" permite que cada ciclo sea mayor al anterior,\n",
    "# en este caso el doble del anterior\n",
    "\n",
    "# Esta vez no reseteamos los parametros\n",
    "# pero vamos a disminuir el learning rate\n",
    "\n",
    "cycle_learner = CycleLearner(lr/2, nb, n_cycle=3, cycle_mult=2)\n",
    "log = model.fit(x_train, y_train, batch_size=bs, epochs=100,\n",
    "                validation_data=[x_test, y_test], callbacks=[cycle_learner])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cycle_learner.plot_lr()\n",
    "show_results(model, log, cycling=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Snapshot ensembles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iniciamos el entrenamiento de forma normal\n",
    "reset_weights(model)\n",
    "cycle_learner = CycleLearner(lr, nb, n_cycle=3, cycle_mult=2)\n",
    "log = model.fit(x_train, y_train, batch_size=bs, epochs=100,\n",
    "                validation_data=[x_test, y_test], callbacks=[cycle_learner])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora activamos los snapshots\n",
    "cycle_learner = CycleLearner(lr/2, nb, n_cycle=3, cycle_len=2, snapshots=True, snapshots_name='mnist_test')\n",
    "log = model.fit(x_train, y_train, batch_size=bs, epochs=100,\n",
    "                validation_data=[x_test, y_test], callbacks=[cycle_learner])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Noten la diferencia de usar \"cycle_len=2\" en lugar de \"cycle_mult=2\" en CycleLearner\n",
    "cycle_learner.plot_lr()\n",
    "show_results(model, log, cycling=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Veamos los archivos creados para los snapshots\n",
    "from pathlib import Path\n",
    "\n",
    "snapshots = Path('snapshots')\n",
    "for file in snapshots.iterdir():\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veamos ahora usando snapshots\n",
    "snapshots_results = np.zeros([10000,10])\n",
    "\n",
    "for file in snapshots.iterdir():\n",
    "    model.load_weights(file)\n",
    "    snapshots_results += model.predict(x_test) / 3\n",
    "    \n",
    "acc = (snapshots_results.argmax(axis=1) == y_test).mean()\n",
    "print(f'Snapshot accuracy = {acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variar la arquitectura de la red y experimentar con las técnicas vistas en clase:\n",
    "* Weight initialization.\n",
    "* Regularización (Dropout, BatchNormalization).\n",
    "* Distintos algoritmos de optimización."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPLETAR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Otra base de datos para practicar:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` python\n",
    "from keras.datasets import fashion_mnist\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPLETAR"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "308.2px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
